{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mehulgoyal353/NutriChat/blob/main/RAG_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing required libraries"
      ],
      "metadata": {
        "id": "EBzaWTziLv_4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UUs6mlCsv5XT",
        "outputId": "4a5acc05-a5eb-4a41-9efd-7dd04692f862"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Running in Google Collab, installing requirements.\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Collecting torch\n",
            "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/779.1 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:01:23\u001b[0m"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if \"COLAB_GPU\" in os.environ:\n",
        "  print(\"[INFO] Running in Google Collab, installing requirements.\")\n",
        "  !pip install -U torch\n",
        "  !pip install PyMuPDF\n",
        "  !pip install tqdm\n",
        "  !pip install sentence-transformers\n",
        "  !pip install accelerate\n",
        "  !pip install bitsandbytes\n",
        "  !pip install flash-attn --no-build-isolation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading and saving the required pdf"
      ],
      "metadata": {
        "id": "LgqhHc1ZyC-o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yB7WoEsr9Z8X"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "pdf_path = \"human-nutrition-text.pdf\"\n",
        "\n",
        "if not os.path.exists(pdf_path):\n",
        "  print(\"File doesn't exist, downloading...\")\n",
        "  url = \"https://pressbooks.oer.hawaii.edu/humannutrition2/open/download?type=pdf\"\n",
        "  filename = pdf_path\n",
        "  response = requests.get(url)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    with open(filename, \"wb\") as file:\n",
        "      file.write(response.content)\n",
        "    print(f\"The file has been downloaded ans saved as {filename}\")\n",
        "  else:\n",
        "    print(f\"Failed to download this file. Status code: {response.status_code}\")\n",
        "\n",
        "else:\n",
        "  print(f\"File {pdf_path} exists.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Basic data pre processing"
      ],
      "metadata": {
        "id": "Eh2ps_n4yNex"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EekKY-yVNGED"
      },
      "outputs": [],
      "source": [
        "import fitz\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def text_formatter(text: str) -> str:\n",
        "  cleaned_text = text.replace(\"\\n\", \" \").strip()\n",
        "  return cleaned_text\n",
        "\n",
        "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
        "  doc = fitz.open(pdf_path)\n",
        "  pages_and_texts = []\n",
        "  for page_number, page in tqdm(enumerate(doc)):\n",
        "    text = page.get_text()\n",
        "    text = text_formatter(text)\n",
        "    pages_and_texts.append({\"page_number\": page_number - 41,\n",
        "                          \"page_char_count\": len(text),\n",
        "                          \"page_word_count\": len(text.split(\" \")),\n",
        "                          \"page_sentence_count\": len(text.split(\".\")),\n",
        "                          \"page_token_count\": len(text)/4,\n",
        "                          \"text\": text})\n",
        "  return pages_and_texts\n",
        "\n",
        "pages_and_texts = open_and_read_pdf(pdf_path = pdf_path)\n",
        "pages_and_texts[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDMFZu7SQPZ4"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "random.sample(pages_and_texts, k = 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Converting raw data into dataframe"
      ],
      "metadata": {
        "id": "9x0zGrAIycgc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GQM-LKIQgJ2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(pages_and_texts)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79kjlX3L6RdD"
      },
      "outputs": [],
      "source": [
        "df.describe().round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Separating sentences using Spacy's Sentencizer"
      ],
      "metadata": {
        "id": "SLCRfLN7yrI3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hgBGBoH7ecr"
      },
      "outputs": [],
      "source": [
        "from spacy.lang.en import English\n",
        "\n",
        "nlp = English()\n",
        "nlp.add_pipe(\"sentencizer\")\n",
        "\n",
        "doc = nlp(\"This is a sentence. This is another sentence.\")\n",
        "assert len(list(doc.sents)) == 2\n",
        "\n",
        "list(doc.sents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdvU_NCb75sz"
      },
      "outputs": [],
      "source": [
        "for item in tqdm(pages_and_texts):\n",
        "  item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
        "  item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
        "  item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c-VkcpU83YU"
      },
      "outputs": [],
      "source": [
        "random.sample(pages_and_texts, k = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Im5G98zt9CB7"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(pages_and_texts)\n",
        "df.describe().round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Forming chunks of data"
      ],
      "metadata": {
        "id": "c3_dq5L3zDjG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPClr0gi9S6h"
      },
      "outputs": [],
      "source": [
        "num_sentence_chunk_size = 10;\n",
        "def split_list(input_list: list,\n",
        "               slice_size: int) -> list[list[str]]:\n",
        "  return [input_list[i: i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
        "\n",
        "for item in tqdm(pages_and_texts):\n",
        "  item[\"sentence_chunks\"] = split_list(input_list = item[\"sentences\"],\n",
        "                                       slice_size = num_sentence_chunk_size)\n",
        "  item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6erbPZja_V63"
      },
      "outputs": [],
      "source": [
        "random.sample(pages_and_texts, k = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dspV9l-E_iJz"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(pages_and_texts)\n",
        "df.describe().round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Formatting to get chunk data"
      ],
      "metadata": {
        "id": "3ZVgm2WWzxCM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHYQ5I6u_4sh"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "pages_and_chunks = []\n",
        "for item in tqdm(pages_and_texts):\n",
        "  for sentence_chunk in item[\"sentence_chunks\"]:\n",
        "    chunk_dict = {}\n",
        "    chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
        "\n",
        "    joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
        "    joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk)\n",
        "    chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
        "\n",
        "    chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
        "    chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
        "    chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4\n",
        "\n",
        "    pages_and_chunks.append(chunk_dict)\n",
        "\n",
        "len(pages_and_chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYcuqBPgANIW"
      },
      "outputs": [],
      "source": [
        "random.sample(pages_and_chunks, k = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TB_130PDRQv"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(pages_and_chunks)\n",
        "df.describe().round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Removing pages with useless data"
      ],
      "metadata": {
        "id": "WXsr4nZIz7HD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKavxqBKDi-S"
      },
      "outputs": [],
      "source": [
        "min_token_length = 30\n",
        "for row in df[df[\"chunk_token_count\"] <= min_token_length].sample(5).iterrows():\n",
        "  print(f'Chunk token count: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"sentence_chunk\"]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7t0z4oTjEiiP"
      },
      "outputs": [],
      "source": [
        "pages_and_chunks_over_min_token_length = df[df[\"chunk_token_count\"] > min_token_length].to_dict(orient = \"records\")\n",
        "pages_and_chunks_over_min_token_length[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Embedding the processed data"
      ],
      "metadata": {
        "id": "70J7GhkX0Gp2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QWihb8VBE-8v"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "embedding_model = SentenceTransformer(model_name_or_path = \"sentence-transformers/all-mpnet-base-v2\",\n",
        "                                      device = \"cuda\")\n",
        "sentences = [\n",
        "    \"My name is Mehul Goyal.\",\n",
        "    \"A few of my hobbies are music and watching anime.\",\n",
        "    \"This is an example list to check how the mpnet embedding model works.\",\n",
        "    \"I have nothing else to write, you know?\"\n",
        "]\n",
        "embeddings = embedding_model.encode(sentences)\n",
        "embeddings_dict = dict(zip(sentences, embeddings))\n",
        "\n",
        "for sentence, embedding in embeddings_dict.items():\n",
        "  print(\"Sentence: \", sentence)\n",
        "  print(\"Embedding: \", embedding)\n",
        "  print(\"Embedding size: \", embedding.shape)\n",
        "  print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ohgklCbLZnB"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "embedding_model.to(\"cuda\")\n",
        "for item in tqdm(pages_and_chunks_over_min_token_length):\n",
        "  item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9DDijPjMYaW"
      },
      "outputs": [],
      "source": [
        "text_chunks = [item[\"sentence_chunk\"] for item in pages_and_chunks_over_min_token_length]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Wbzrz_iZNIO4"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "text_chunk_embeddings = embedding_model.encode(text_chunks,\n",
        "                                               batch_size = 32,\n",
        "                                               convert_to_tensor = True)\n",
        "text_chunk_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W25UaL5YWsrJ"
      },
      "outputs": [],
      "source": [
        "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks_over_min_token_length)\n",
        "embeddings_df_save_path = \"text_chunks_and_embeddings.csv\"\n",
        "text_chunks_and_embeddings_df.to_csv(embeddings_df_save_path, index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fccuj_TSkSs4"
      },
      "outputs": [],
      "source": [
        "text_chunks_and_embeddings_df_load = pd.read_csv(embeddings_df_save_path)\n",
        "text_chunks_and_embeddings_df_load.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Adding the embeddings to the text_and_chunks dictionary"
      ],
      "metadata": {
        "id": "ivD-vLYi2beI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xdJadjzlfLx"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "text_chunks_and_embeddings_df = pd.read_csv(\"text_chunks_and_embeddings.csv\")\n",
        "text_chunks_and_embeddings_df[\"embedding\"] = text_chunks_and_embeddings_df[\"embedding\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep = \" \"))\n",
        "\n",
        "pages_and_chunks = text_chunks_and_embeddings_df.to_dict(orient = \"records\")\n",
        "\n",
        "embeddings = torch.tensor(np.array(text_chunks_and_embeddings_df[\"embedding\"].to_list()), dtype = torch.float32).to(device)\n",
        "embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2gXpvBnpCif"
      },
      "outputs": [],
      "source": [
        "text_chunks_and_embeddings_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LPvy9VL9pk9F"
      },
      "outputs": [],
      "source": [
        "embeddings[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Embedding the input query"
      ],
      "metadata": {
        "id": "G3khcyJV2txe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQpGKrJjpv_n"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "embedding_model = SentenceTransformer(model_name_or_path = \"all-mpnet-base-v2\",\n",
        "                                      device = device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yydh9q6msBOW"
      },
      "outputs": [],
      "source": [
        "query = \"macronutrients functions\"\n",
        "print(f\"Query: {query}\")\n",
        "\n",
        "query_embedding = embedding_model.encode(query, convert_to_tensor = True)\n",
        "\n",
        "from time import perf_counter as timer\n",
        "\n",
        "start_time = timer()\n",
        "dot_scores = util.dot_score(a = query_embedding, b = embeddings)[0]\n",
        "end_time = timer()\n",
        "\n",
        "print(f\"Time taken to get score on {len(embeddings)} embeddings: {end_time - start_time:.5f} seconds.\")\n",
        "\n",
        "top_results_dot_product = torch.topk(dot_scores, k = 5)\n",
        "top_results_dot_product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8vq0Tbrt6j1"
      },
      "outputs": [],
      "source": [
        "larger_embeddings = torch.randn(100*embeddings.shape[0], 768).to(device)\n",
        "print(f\"Embeddings shape: {larger_embeddings.shape}\")\n",
        "\n",
        "start_time = timer()\n",
        "dot_scores = util.dot_score(a = query_embedding, b = larger_embeddings)[0]\n",
        "end_time = timer()\n",
        "\n",
        "print(f\"Time taken to get scores on {len(larger_embeddings)} embeddings: {end_time - start_time:.5f} seconds.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Formatting the query"
      ],
      "metadata": {
        "id": "tSz2_t243M8N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POqigxthvaQP"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "\n",
        "def print_wrapped(text, wrap_length = 80):\n",
        "  wrapped_text = textwrap.fill(text, wrap_length)\n",
        "  print(wrapped_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "d6q97ZpLw1S4"
      },
      "outputs": [],
      "source": [
        "print(f\"Query: '{query}'\\n\")\n",
        "print(\"Results:\")\n",
        "\n",
        "for score, idx in zip(top_results_dot_product[0], top_results_dot_product[1]):\n",
        "  print(f\"Score: {score:.4f}\")\n",
        "  print(\"Text:\")\n",
        "  print_wrapped(pages_and_chunks[idx][\"sentence_chunk\"])\n",
        "\n",
        "  print(f\"Page number: {pages_and_chunks[idx]['page_number']}\")\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBh4_LNMyLQ8"
      },
      "outputs": [],
      "source": [
        "import fitz\n",
        "\n",
        "pdf_path = \"human-nutrition-text.pdf\"\n",
        "doc = fitz.open(pdf_path)\n",
        "page = doc.load_page(5 + 41)\n",
        "\n",
        "img = page.get_pixmap(dpi = 300)\n",
        "doc.close()\n",
        "\n",
        "img_array = np.frombuffer(img.samples_mv,\n",
        "                          dtype = np.uint8).reshape((img.h, img.w, img.n))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize = (13, 10))\n",
        "plt.imshow(img_array)\n",
        "plt.title(f\"Query: '{query}' | Most relevant page:\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Retrieving chunks of data related to the query"
      ],
      "metadata": {
        "id": "4AwvRFb_3XpE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vIehIh2z10W"
      },
      "outputs": [],
      "source": [
        "def retrieve_relevant_resources(query: str,\n",
        "                                embeddings: torch.tensor,\n",
        "                                model: SentenceTransformer = embedding_model,\n",
        "                                n_resources_to_return: int = 5,\n",
        "                                print_time: bool = True):\n",
        "  query_embedding = model.encode(query,\n",
        "                                 convert_to_tensor = True)\n",
        "\n",
        "  start_time = timer()\n",
        "  dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
        "  end_time = timer()\n",
        "\n",
        "  if print_time:\n",
        "    print(f\"[INFO] Time taken to get scores on {len(embeddings)} embeddings : {end_time - start_time:.5f} seconds.\")\n",
        "\n",
        "  scores, indices = torch.topk(input = dot_scores,\n",
        "                               k = n_resources_to_return)\n",
        "\n",
        "  return scores, indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpAGPcM62GBm"
      },
      "outputs": [],
      "source": [
        "def print_top_results_and_scores(query: str,\n",
        "                                 embeddings: torch.tensor,\n",
        "                                 pages_and_chunks: list[dict] = pages_and_chunks,\n",
        "                                 n_resources_to_return: int = 5):\n",
        "\n",
        "  scores, indices = retrieve_relevant_resources(query = query,\n",
        "                                                embeddings = embeddings,\n",
        "                                                n_resources_to_return = n_resources_to_return)\n",
        "  print(f\"Query: {query}\\n\")\n",
        "  print(\"Results:\")\n",
        "\n",
        "  for score, index in zip(scores, indices):\n",
        "    print(f\"Score: {score:.4f}\")\n",
        "    print_wrapped(pages_and_chunks[index][\"sentence_chunk\"])\n",
        "    print(f\"Page number: {pages_and_chunks[index]['page_number']}\")\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvErhxdt3rJD"
      },
      "outputs": [],
      "source": [
        "query = \"symptoms of Pellagra\"\n",
        "\n",
        "scores, indices = retrieve_relevant_resources(query = query,\n",
        "                                              embeddings = embeddings)\n",
        "scores, indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hs19fTyz3-sH"
      },
      "outputs": [],
      "source": [
        "print_top_results_and_scores(query = query,\n",
        "                             embeddings = embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Checking for the most optimal LLM according to the available GPU memory"
      ],
      "metadata": {
        "id": "-M8cijC-5zSq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pa0VZBqt4MUO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "gpu_memory_bytes = torch.cuda.get_device_properties(0).total_memory\n",
        "gpu_memory_gb = round(gpu_memory_bytes / (2**30))\n",
        "print(f\"Available GPU memory: {gpu_memory_gb} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fe6HHuOC-YRF"
      },
      "outputs": [],
      "source": [
        "if gpu_memory_gb < 5.1:\n",
        "    print(f\"Your available GPU memory is {gpu_memory_gb}GB, you may not have enough memory to run a Gemma LLM locally without quantization.\")\n",
        "elif gpu_memory_gb < 8.1:\n",
        "    print(f\"GPU memory: {gpu_memory_gb} | Recommended model: Gemma 2B in 4-bit precision.\")\n",
        "    use_quantization_config = True\n",
        "    model_id = \"google/gemma-2b-it\"\n",
        "elif gpu_memory_gb < 19.0:\n",
        "    print(f\"GPU memory: {gpu_memory_gb} | Recommended model: Gemma 2B in float16 or Gemma 7B in 4-bit precision.\")\n",
        "    use_quantization_config = False\n",
        "    model_id = \"google/gemma-2b-it\"\n",
        "elif gpu_memory_gb > 19.0:\n",
        "    print(f\"GPU memory: {gpu_memory_gb} | Recommend model: Gemma 7B in 4-bit or float16 precision.\")\n",
        "    use_quantization_config = False\n",
        "    model_id = \"google/gemma-7b-it\"\n",
        "\n",
        "print(f\"use_quantization_config set to: {use_quantization_config}\")\n",
        "print(f\"model_id set to: {model_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Getting the HuggingFace user token to access the model's gated repo"
      ],
      "metadata": {
        "id": "nD72x0a56AJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import os\n",
        "os.environ['HUGGINGFACE_TOKEN'] = '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'"
      ],
      "metadata": {
        "id": "z66VjpERCWCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Getting the model ready"
      ],
      "metadata": {
        "id": "b64almPR6h3o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcxEb6WtAz-G"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers.utils import is_flash_attn_2_available\n",
        "from transformers import BitsAndBytesConfig\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(token=os.getenv('HUGGINGFACE_TOKEN'))\n",
        "\n",
        "quanitization_config = BitsAndBytesConfig(load_in_4bit = True,\n",
        "                                          bnb_4bit_compute_dtype = torch.float16)\n",
        "\n",
        "if (is_flash_attn_2_available()) and (torch.cuda.get_device_capability(0)[0]>=8):\n",
        "  attn_implementation = \"flash_attention_2\"\n",
        "else:\n",
        "  attn_implementation = \"sdpa\"\n",
        "\n",
        "print(f\"[INFO] Using attention implementation: {attn_implementation}\")\n",
        "\n",
        "model_id = model_id\n",
        "print(f\"[INFO] Using model id: {model_id}\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path = model_id, use_auth_token=True)\n",
        "\n",
        "llm_model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path = model_id,\n",
        "                                                 use_auth_token=True,\n",
        "                                                 torch_dtype = torch.float16,\n",
        "                                                 quantization_config = quantization_config if use_quantization_config else None,\n",
        "                                                 low_cpu_mem_usage = False,\n",
        "                                                 attn_implementation = attn_implementation)\n",
        "if not use_quantization_config:\n",
        "  llm_model.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_model"
      ],
      "metadata": {
        "id": "qsvxnHdVDDZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_num_params(model: torch.nn.Module):\n",
        "    return sum([param.numel() for param in model.parameters()])\n",
        "\n",
        "get_model_num_params(llm_model)"
      ],
      "metadata": {
        "id": "_2sk5Dg_D9d4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_mem_size(model: torch.nn.Module):\n",
        "\n",
        "    mem_params = sum([param.nelement() * param.element_size() for param in model.parameters()])\n",
        "    mem_buffers = sum([buf.nelement() * buf.element_size() for buf in model.buffers()])\n",
        "\n",
        "    model_mem_bytes = mem_params + mem_buffers\n",
        "    model_mem_mb = model_mem_bytes / (1024**2)\n",
        "    model_mem_gb = model_mem_bytes / (1024**3)\n",
        "\n",
        "    return {\"model_mem_bytes\": model_mem_bytes,\n",
        "            \"model_mem_mb\": round(model_mem_mb, 2),\n",
        "            \"model_mem_gb\": round(model_mem_gb, 2)}\n",
        "\n",
        "get_model_mem_size(llm_model)"
      ],
      "metadata": {
        "id": "xGkQbV5OEGcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Making a chat template for the query"
      ],
      "metadata": {
        "id": "3FbmlCZL74F8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"What is micronutrients?\"\n",
        "print(f\"Input text:\\n{input_text}\")\n",
        "\n",
        "dialogue_template = [\n",
        "    {\"role\": \"user\",\n",
        "     \"content\": input_text}\n",
        "]\n",
        "\n",
        "prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
        "                                       tokenize=False,\n",
        "                                       add_generation_prompt=True)\n",
        "print(f\"\\nPrompt (formatted):\\n{prompt}\")"
      ],
      "metadata": {
        "id": "2K_sECKgELkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "print(f\"Model input (tokenized):\\n{input_ids}\\n\")\n",
        "\n",
        "outputs = llm_model.generate(**input_ids,\n",
        "                             max_new_tokens=256)\n",
        "print(f\"Model output (tokens):\\n{outputs[0]}\\n\")"
      ],
      "metadata": {
        "id": "SxCLz_k6ESgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_decoded = tokenizer.decode(outputs[0])\n",
        "print(f\"Model output (decoded):\\n{outputs_decoded}\\n\")"
      ],
      "metadata": {
        "id": "6UaNaTBAEkAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Input text: {input_text}\\n\")\n",
        "print(f\"Output text:\\n{outputs_decoded.replace(prompt, '').replace('<bos>', '').replace('<eos>', '')}\")"
      ],
      "metadata": {
        "id": "kRfq3eePEq0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gpt4_questions = [\n",
        "#     \"What are the macronutrients, and what roles do they play in the human body?\",\n",
        "#     \"How do vitamins and minerals differ in their roles and importance for health?\",\n",
        "#     \"Describe the process of digestion and absorption of nutrients in the human body.\",\n",
        "#     \"What role does fibre play in digestion? Name five fibre containing foods.\",\n",
        "#     \"Explain the concept of energy balance and its importance in weight management.\"\n",
        "# ]\n",
        "\n",
        "# manual_questions = [\n",
        "#     \"How often should infants be breastfed?\",\n",
        "#     \"What are symptoms of pellagra?\",\n",
        "#     \"How does saliva help with digestion?\",\n",
        "#     \"What is the RDI for protein per day?\",\n",
        "#     \"water soluble vitamins\"\n",
        "# ]\n",
        "\n",
        "# query_list = gpt4_questions + manual_questions"
      ],
      "metadata": {
        "id": "E04ke6TUE0fM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "# query = random.choice(query_list)\n",
        "\n",
        "# print(f\"Query: {query}\")\n",
        "\n",
        "# scores, indices = retrieve_relevant_resources(query=query,\n",
        "#                                               embeddings=embeddings)\n",
        "# scores, indices"
      ],
      "metadata": {
        "id": "0dg378K6E5sK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def prompt_formatter(query: str,\n",
        "#                      context_items: list[dict]) -> str:\n",
        "\n",
        "#     context = \"- \" + \"\\n- \".join([item[\"sentence_chunk\"] for item in context_items])\n",
        "\n",
        "#     base_prompt = \"\"\"Based on the following context items, please answer the query.\n",
        "# Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
        "# Don't return the thinking, only return the answer.\n",
        "# Make sure your answers are as explanatory as possible.\n",
        "# Use the following examples as reference for the ideal answer style.\n",
        "# \\nExample 1:\n",
        "# Query: What are the fat-soluble vitamins?\n",
        "# Answer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\n",
        "# \\nExample 2:\n",
        "# Query: What are the causes of type 2 diabetes?\n",
        "# Answer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\n",
        "# \\nExample 3:\n",
        "# Query: What is the importance of hydration for physical performance?\n",
        "# Answer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\n",
        "# \\nNow use the following context items to answer the user query:\n",
        "# {context}\n",
        "# \\nRelevant passages: <extract relevant passages from the context here>\n",
        "# User query: {query}\n",
        "# Answer:\"\"\"\n",
        "\n",
        "#     base_prompt = base_prompt.format(context=context, query=query)\n",
        "\n",
        "#     dialogue_template = [\n",
        "#         {\"role\": \"user\",\n",
        "#         \"content\": base_prompt}\n",
        "#     ]\n",
        "\n",
        "#     prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
        "#                                           tokenize=False,\n",
        "#                                           add_generation_prompt=True)\n",
        "#     return prompt"
      ],
      "metadata": {
        "id": "X6tn3j6ZE9CO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# query = random.choice(query_list)\n",
        "# print(f\"Query: {query}\")\n",
        "\n",
        "# scores, indices = retrieve_relevant_resources(query=query,\n",
        "#                                               embeddings=embeddings)\n",
        "\n",
        "# context_items = [pages_and_chunks[i] for i in indices]\n",
        "\n",
        "# prompt = prompt_formatter(query=query,\n",
        "#                           context_items=context_items)\n",
        "# print(prompt)"
      ],
      "metadata": {
        "id": "I-55xGx4FFpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def ask(query,\n",
        "#         temperature=0.7,\n",
        "#         max_new_tokens=512,\n",
        "#         format_answer_text=True,\n",
        "#         return_answer_only=True):\n",
        "\n",
        "#     scores, indices = retrieve_relevant_resources(query=query,\n",
        "#                                                   embeddings=embeddings)\n",
        "\n",
        "#     context_items = [pages_and_chunks[i] for i in indices]\n",
        "\n",
        "#     for i, item in enumerate(context_items):\n",
        "#         item[\"score\"] = scores[i].cpu()\n",
        "\n",
        "#     prompt = prompt_formatter(query=query,\n",
        "#                               context_items=context_items)\n",
        "\n",
        "#     input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "#     outputs = llm_model.generate(**input_ids,\n",
        "#                                  temperature=temperature,\n",
        "#                                  do_sample=True,\n",
        "#                                  max_new_tokens=max_new_tokens)\n",
        "\n",
        "#     output_text = tokenizer.decode(outputs[0])\n",
        "\n",
        "#     if format_answer_text:\n",
        "#         output_text = output_text.replace(prompt, \"\").replace(\"<bos>\", \"\").replace(\"<eos>\", \"\").replace(\"Sure, here is the answer to the user query:\\n\\n\", \"\")\n",
        "\n",
        "#     if return_answer_only:\n",
        "#         return output_text\n",
        "\n",
        "#     return output_text, context_items"
      ],
      "metadata": {
        "id": "KgHuzWzeFISt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# query = random.choice(query_list)\n",
        "# print(f\"Query: {query}\")\n",
        "\n",
        "# answer, context_items = ask(query=query,\n",
        "#                             temperature=0.7,\n",
        "#                             max_new_tokens=512,\n",
        "#                             return_answer_only=False)\n",
        "\n",
        "# print(f\"Answer:\\n\")\n",
        "# print_wrapped(answer)\n",
        "# print(f\"Context items:\")\n",
        "# context_items"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mYR6uepKFXa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8_QguClEF0Dc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}